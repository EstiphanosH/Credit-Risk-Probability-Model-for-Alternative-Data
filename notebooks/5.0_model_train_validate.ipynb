{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8f3688",
   "metadata": {},
   "source": [
    "# Model Training and Validation\n",
    "\n",
    "## 1. Data Splitting Strategy\n",
    "\n",
    "We use a three-way split for robust validation:\n",
    "\n",
    "- **Training (70%)**: Used for model fitting\n",
    "- **Validation (15%)**: Used for hyperparameter tuning\n",
    "- **Test (15%)**: Used for final evaluation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156f551",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# Credit Risk Model Training & Validation\n",
    "## Step-by-Step Implementation\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 1. Setup Environment\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Install required packages\n",
    "!pip install mlflow scikit-learn xgboost pandas numpy matplotlib seaborn joblib\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import mlflow\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, roc_curve)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Credit_Risk_Model\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 2. Load Processed Data\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Load processed data\n",
    "data_path = \"../data/processed/processed_data.csv\"\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(\"Processed data not found. Run data_processing.py first\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(\"\\nData columns:\")\n",
    "print(data.columns.tolist())\n",
    "print(\"\\nClass distribution:\")\n",
    "print(data[\"is_high_risk\"].value_counts(normalize=True))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 3. Time-Based Data Splitting\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def time_based_split(data, time_col='TransactionStartTime'):\n",
    "    \"\"\"Split data into train/validation/test sets with time ordering\"\"\"\n",
    "    # Sort by transaction time\n",
    "    data = data.sort_values(time_col).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_end = int(0.7 * len(data))\n",
    "    val_end = train_end + int(0.15 * len(data))\n",
    "    \n",
    "    # Create splits\n",
    "    train = data.iloc[:train_end]\n",
    "    val = data.iloc[train_end:val_end]\n",
    "    test = data.iloc[val_end:]\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "# Split data\n",
    "train, val, test = time_based_split(data)\n",
    "\n",
    "print(f\"Train size: {len(train)} ({len(train)/len(data):.1%})\")\n",
    "print(f\"Validation size: {len(val)} ({len(val)/len(data):.1%})\")\n",
    "print(f\"Test size: {len(test)} ({len(test)/len(data):.1%})\")\n",
    "\n",
    "# Visualize time distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(pd.to_datetime(train['TransactionStartTime']), label='Train', alpha=0.7)\n",
    "plt.plot(pd.to_datetime(val['TransactionStartTime']), label='Validation', alpha=0.7)\n",
    "plt.plot(pd.to_datetime(test['TransactionStartTime']), label='Test', alpha=0.7)\n",
    "plt.title(\"Time-Based Data Split\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Transaction Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 4. Prepare Datasets\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Separate features and target\n",
    "X_train = train.drop(columns=[\"is_high_risk\"])\n",
    "y_train = train[\"is_high_risk\"]\n",
    "\n",
    "X_val = val.drop(columns=[\"is_high_risk\"])\n",
    "y_val = val[\"is_high_risk\"]\n",
    "\n",
    "X_test = test.drop(columns=[\"is_high_risk\"])\n",
    "y_test = test[\"is_high_risk\"]\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 5. Create Preprocessing Pipeline\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Numeric preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Full preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 6. Model Training & Hyperparameter Tuning\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Define models and hyperparameters\n",
    "models = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver='liblinear', random_state=42, max_iter=1000),\n",
    "        \"params\": {\n",
    "            'classifier__C': [0.01, 0.1, 1],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            'classifier__n_estimators': [100, 200],\n",
    "            'classifier__max_depth': [10, None],\n",
    "            'classifier__min_samples_split': [5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        \"params\": {\n",
    "            'classifier__n_estimators': [100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1],\n",
    "            'classifier__max_depth': [3, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Time-series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "best_models = {}\n",
    "mlflow.set_experiment(\"Credit_Risk_Model\")\n",
    "\n",
    "# %%\n",
    "for name, config in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{name}_Experiment\", nested=True):\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', config[\"model\"])\n",
    "        ])\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=config[\"params\"],\n",
    "            cv=tscv,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        \n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_auc)\n",
    "        mlflow.log_metric(\"val_accuracy\", accuracy_score(y_val, y_val_pred))\n",
    "        mlflow.log_metric(\"val_precision\", precision_score(y_val, y_val_pred))\n",
    "        mlflow.log_metric(\"val_recall\", recall_score(y_val, y_val_pred))\n",
    "        \n",
    "        # Track best model\n",
    "        best_models[name] = {\n",
    "            \"model\": best_model,\n",
    "            \"val_auc\": val_auc,\n",
    "            \"run_id\": mlflow.active_run().info.run_id\n",
    "        }\n",
    "        \n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 7. Model Selection & Final Evaluation\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Select best model based on validation AUC\n",
    "best_model_name = max(best_models, key=lambda k: best_models[k][\"val_auc\"])\n",
    "best_model = best_models[best_model_name][\"model\"]\n",
    "best_run_id = best_models[best_model_name][\"run_id\"]\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Best model: {best_model_name} (AUC: {best_models[best_model_name]['val_auc']:.4f})\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "with mlflow.start_run(run_name=\"Final_Evaluation\") as run:\n",
    "    # Predict on test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"test_precision\": precision_score(y_test, y_test_pred),\n",
    "        \"test_recall\": recall_score(y_test, y_test_pred),\n",
    "        \"test_f1\": f1_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_model, \n",
    "        \"model\", \n",
    "        registered_model_name=\"CreditRiskModel\"\n",
    "    )\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "        mlflow.log_metric(metric, value)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Low Risk', 'High Risk'],\n",
    "                yticklabels=['Low Risk', 'High Risk'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {metrics[\"test_roc_auc\"]:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"roc_curve.png\")\n",
    "    plt.show()\n",
    "    mlflow.log_artifact(\"roc_curve.png\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 8. Feature Importance Analysis\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Extract feature names\n",
    "feature_names = list(numeric_features) + list(\n",
    "    best_model.named_steps['preprocessor']\n",
    "    .named_transformers_['cat']\n",
    "    .named_steps['onehot']\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "\n",
    "# Plot feature importance\n",
    "if hasattr(best_model.named_steps['classifier'], 'feature_importances_'):\n",
    "    importances = best_model.named_steps['classifier'].feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False).head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"feature_importance.png\")\n",
    "    plt.show()\n",
    "    mlflow.log_artifact(\"feature_importance.png\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    importance_df.to_csv(\"feature_importances.csv\", index=False)\n",
    "    mlflow.log_artifact(\"feature_importances.csv\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 9. Save Model\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Save model locally\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(best_model, \"../models/credit_risk_model.pkl\")\n",
    "print(\"Model saved to models/credit_risk_model.pkl\")\n",
    "\n",
    "# Log model path\n",
    "mlflow.log_param(\"model_path\", \"../models/credit_risk_model.pkl\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 10. MLflow Tracking\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Show MLflow experiment UI link\n",
    "print(\"\\nMLflow Experiment Tracking:\")\n",
    "print(\"Run the following command to view results:\")\n",
    "print(\"mlflow ui --backend-store-uri sqlite:///mlflow.db\")\n",
    "print(f\"Then visit: http://localhost:5000\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
